{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# Backpropagation Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 1 Avoiding Overfit: Early Stopping and Loss Regularization\n",
        "\n",
        "### 1.1 (10%) No overfit avoidance\n",
        "Train the sklearn [MLP classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) on the [Iris Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/iris.arff).  Use 3 output nodes (1 per class). Expanding the one output variable into 3 is called one-hot encoding or dummy variable encoding. There are lots of ways to implement this including the Pandas get_dummies method. This experiment is set up to run a little longer to better see the effects of overfit.  Be patient as there are lots of hidden nodes and a high max iterations setting.\n",
        "\n",
        "Use default parameters except for the following:\n",
        "- hidden_layer_sizes = [64] - One hidden layer with 64 hidden nodes\n",
        "- activation = 'logistic'\n",
        "- solver = 'sgd'\n",
        "- alpha = 0\n",
        "- batch_size = 1\n",
        "- learning_rate_init = 0.01\n",
        "- shuffle = True\n",
        "- momentum = 0\n",
        "- n_iter_no_change = 50\n",
        "- max_iterations = 1000\n",
        "\n",
        "Use a random 80/20 split of the data.  Run it a few times with different random training/test splits and give average values for\n",
        "- Number of iterations until convergence\n",
        "- Training set accuracy\n",
        "- Test set accuracy\n",
        "For one run observe the softmax probabilities on the test set using clf.predict_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpGY5Th5vpS9",
        "outputId": "9c94bd34-0aee-4fa3-efb2-9ab68add75bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax probabilities on the test set for one run:\n",
            "[[1.21699622e-03 9.98470865e-01 3.12139063e-04]\n",
            " [2.30364220e-03 9.97586665e-01 1.09692837e-04]\n",
            " [9.97158163e-01 2.84183712e-03 2.72460321e-16]\n",
            " [9.96742528e-01 3.25747173e-03 1.14060026e-15]\n",
            " [9.98593031e-01 1.40696864e-03 6.35038524e-17]\n",
            " [2.65176159e-07 3.49233454e-02 9.65076389e-01]\n",
            " [9.97735477e-01 2.26452279e-03 1.94748388e-16]\n",
            " [3.95550328e-07 4.54340350e-02 9.54565569e-01]\n",
            " [1.45423401e-08 3.79743585e-03 9.96202550e-01]\n",
            " [9.98777707e-01 1.22229270e-03 5.71990854e-17]\n",
            " [2.35931511e-07 3.80313690e-02 9.61968395e-01]\n",
            " [2.37512821e-04 9.90961224e-01 8.80126358e-03]\n",
            " [9.94575525e-01 5.42447507e-03 1.86469419e-15]\n",
            " [9.98580756e-01 1.41924419e-03 5.92859592e-17]\n",
            " [2.20803665e-04 9.74056925e-01 2.57222717e-02]\n",
            " [9.98770447e-01 1.22955291e-03 5.95583100e-17]\n",
            " [1.72710882e-06 1.68249449e-01 8.31748824e-01]\n",
            " [9.95433308e-01 4.56669227e-03 9.58819078e-16]\n",
            " [3.71299195e-09 2.03425509e-03 9.97965741e-01]\n",
            " [9.97176087e-01 2.82391332e-03 4.18138139e-16]\n",
            " [9.98710638e-01 1.28936168e-03 7.50946248e-17]\n",
            " [6.03630259e-10 7.27554195e-04 9.99272445e-01]\n",
            " [1.09042573e-03 9.98537524e-01 3.72050061e-04]\n",
            " [2.93491890e-06 1.92523680e-01 8.07473385e-01]\n",
            " [4.94753067e-09 2.60520488e-03 9.97394790e-01]\n",
            " [9.95814561e-01 4.18543899e-03 1.04504474e-15]\n",
            " [3.01161611e-08 9.03849598e-03 9.90961474e-01]\n",
            " [9.99612239e-01 3.87761074e-04 2.91812571e-18]\n",
            " [1.50614149e-07 2.86528493e-02 9.71347000e-01]\n",
            " [1.27460778e-03 9.98490401e-01 2.34991520e-04]]\n",
            "Average number of iterations until convergence: 308.40\n",
            "Average training set accuracy: 0.9733\n",
            "Average test set accuracy: 0.9733\n"
          ]
        }
      ],
      "source": [
        "#Iris with no regularization\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Parameters as specified\n",
        "clf_params = {\n",
        "    'hidden_layer_sizes': [64],\n",
        "    'activation': 'logistic',\n",
        "    'solver': 'sgd',\n",
        "    'alpha': 0,\n",
        "    'batch_size': 1,\n",
        "    'learning_rate_init': 0.01,\n",
        "    'shuffle': True,\n",
        "    'momentum': 0,\n",
        "    'n_iter_no_change': 50,\n",
        "    'max_iter': 1000,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "n_runs = 5  # Number of runs\n",
        "n_iter_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "for i in range(n_runs):\n",
        "    # Split the data with a different random state each time\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Initialize and train the classifier\n",
        "    clf = MLPClassifier(**clf_params)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Record metrics\n",
        "    n_iter_list.append(clf.n_iter_)\n",
        "    train_acc_list.append(clf.score(X_train, y_train))\n",
        "    test_acc_list.append(clf.score(X_test, y_test))\n",
        "\n",
        "    # For one run, observe the softmax probabilities on the test set\n",
        "    if i == 0:\n",
        "        probs = clf.predict_proba(X_test)\n",
        "        print(\"Softmax probabilities on the test set for one run:\")\n",
        "        print(probs)\n",
        "\n",
        "# Compute and print average values\n",
        "print(f\"Average number of iterations until convergence: {np.mean(n_iter_list):.2f}\")\n",
        "print(f\"Average training set accuracy: {np.mean(train_acc_list):.4f}\")\n",
        "print(f\"Average test set accuracy: {np.mean(test_acc_list):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QyWjEM4vpS-"
      },
      "source": [
        "Using specific hyperparameters, such as a single hidden layer with 64 neurons and logistic activation, my algorithm trains an `MLPClassifier` on the Iris dataset without regularization (`alpha=0`). To calculate average metrics, it runs five times using various random splits. High test and training accuracies (averaging roughly 97.33%) are shown by the findings, suggesting that the model generalizes effectively in spite of irregularities and possible overfitting brought on by the big hidden layer. The model usually converges before reaching the maximum of 1000 iterations, with an average number of iterations until convergence of about 308.4. The model's confidence levels across several classes for the test set predictions are depicted by the softmax probabilities that are shown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a537lA5MvpS-"
      },
      "source": [
        "### 1.2 (10%) Early Stopping (Validation Set)\n",
        "\n",
        "- Do the same as above but his time with early stopping\n",
        "- Use a validation set taken from the training set for your stopping criteria. Using 10-15% of the training set for a validation set is common. You do this simply by setting the MLPClassifier early_stopping, validation_fraction, and n_iter_no_change parameters.\n",
        "- Run it a few times with different training/test splits and give average values for\n",
        "    - Number of iterations until convergence\n",
        "    - Training set accuracy\n",
        "    - Test set accuracy\n",
        "    - Best validation score (MLPClassifer attribute best_validation_score_)\n",
        "- For one run create a graph with validation set accuracy (*y*-axis) vs epochs (*x*-axis). Hint: MLPClassifer attribute validation_scores_\n",
        "\n",
        "Note: Due to the simplicity of and lack of noise in the iris data set you will not see the accuracy improvements that early stopping or loss regularization can give for more complex noisy datasets.  In particular, early stopping will have lower than expected results because with a very small VS taken from a very small training set there is less data to train on and more variance with the VS score.  Thus, you will probably get lower accuracies for VS than normal training for this less typical case.  But at least you will get practice on using early stopping and loss regularization for future data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "vv2Hd6MFvpS-",
        "outputId": "b7df12c6-fdd6-41f6-8fc2-a1b71520d0a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of iterations until convergence: 64.00\n",
            "Average training set accuracy: 0.9600\n",
            "Average test set accuracy: 0.9333\n",
            "Average best validation score: 1.0000\n"
          ]
        }
      ],
      "source": [
        "#Iris with early stopping and validation scores graph\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Parameters as specified\n",
        "clf_params = {\n",
        "    'hidden_layer_sizes': [64],\n",
        "    'activation': 'logistic',\n",
        "    'solver': 'sgd',\n",
        "    'alpha': 0,\n",
        "    'batch_size': 1,\n",
        "    'learning_rate_init': 0.01,\n",
        "    'shuffle': True,\n",
        "    'momentum': 0,\n",
        "    'n_iter_no_change': 50,\n",
        "    'max_iter': 1000,\n",
        "    'early_stopping': True,\n",
        "    'validation_fraction': 0.1,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "n_runs = 5  # Number of runs\n",
        "n_iter_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "best_val_score_list = []\n",
        "\n",
        "for i in range(n_runs):\n",
        "    # Split the data with a different random state each time\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "    # Initialize and train the classifier\n",
        "    clf = MLPClassifier(**clf_params)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Record metrics\n",
        "    n_iter_list.append(clf.n_iter_)\n",
        "    train_acc_list.append(clf.score(X_train, y_train))\n",
        "    test_acc_list.append(clf.score(X_test, y_test))\n",
        "    best_val_score_list.append(clf.best_validation_score_)\n",
        "\n",
        "    # For one run, observe the validation accuracy over epochs\n",
        "    if i == 0:\n",
        "        epochs = np.arange(1, clf.n_iter_ + 1)\n",
        "        plt.plot(epochs, clf.validation_scores_, marker='o')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Validation Accuracy')\n",
        "        plt.title('Validation Accuracy vs. Epochs')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "# Compute and print average values\n",
        "print(f\"Average number of iterations until convergence: {np.mean(n_iter_list):.2f}\")\n",
        "print(f\"Average training set accuracy: {np.mean(train_acc_list):.4f}\")\n",
        "print(f\"Average test set accuracy: {np.mean(test_acc_list):.4f}\")\n",
        "print(f\"Average best validation score: {np.mean(best_val_score_list):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNMATZqjtlxs"
      },
      "source": [
        "Using a validation set that contains 10% of the training data and early stopping, the given code trains an `MLPClassifier` on the Iris dataset. To calculate average metrics, it does five rounds using various random divides. The model uses one hidden layer with 64 neurons, no regularization (`alpha=0`), and logistic activation. When the validation score doesn't increase after 50 iterations, training is prematurely stopped. The findings indicate that the average convergence occurred after 64 epochs, with a 96% training accuracy and a 93.33% test accuracy. Interestingly, the best validation score averages 100%, meaning that at some point, the validation set is performed flawlessly. The validation accuracy plot shows the performance improvement of the model prior to an early stopping event."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnGh1qSWvpS-"
      },
      "source": [
        "### 1.3 (10%) Loss Regularization\n",
        "\n",
        "- Do the same as in 1.1 but his time with loss regularization (Do not do early stopping)\n",
        "- Run it with different L2 regularization parameter values (alpha).  The default for alpha is .0001.  Try other values such as .1, .01, .001, .00001, etc. Make a table with each row including:\n",
        "    - The regularization parameter value\n",
        "    - Number of iterations until convergence\n",
        "    - Training set accuracy\n",
        "    - Test set accuracy\n",
        "    - Best loss value (MLPClassifer attribute best_loss_)\n",
        "- Which regularization value gave you the best results?\n",
        "- For your best regularization value do one run and create a graph with loss (*y*-axis) vs epochs (*x*-axis) for the training set (Hint: MLPClassifer attribute loss_curve_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "WvC1IF4kvpS_",
        "outputId": "ea617aee-81db-438d-e0cf-cdb42abdec3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results Table:\n",
            "     alpha  iterations  train_accuracy  test_accuracy  best_loss\n",
            "0  0.10000         112        0.683333       0.600000   0.878413\n",
            "1  0.01000         149        0.975000       0.933333   0.351119\n",
            "2  0.00100         227        0.983333       0.966667   0.096911\n",
            "3  0.00010         293        0.983333       0.966667   0.045655\n",
            "4  0.00001         217        0.983333       0.966667   0.042331\n",
            "\n",
            "Best regularization value (alpha): 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Iris with Loss Regularization\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Parameters as specified (excluding early stopping)\n",
        "common_params = {\n",
        "    'hidden_layer_sizes': [64],\n",
        "    'activation': 'logistic',\n",
        "    'solver': 'sgd',\n",
        "    'batch_size': 1,\n",
        "    'learning_rate_init': 0.01,\n",
        "    'shuffle': True,\n",
        "    'momentum': 0,\n",
        "    'n_iter_no_change': 50,\n",
        "    'max_iter': 1000,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# List of alpha values to try\n",
        "alpha_values = [0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
        "\n",
        "# Initialize lists to store results\n",
        "results = []\n",
        "\n",
        "# Split the data once for fair comparison\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Run the model for each alpha value\n",
        "for alpha in alpha_values:\n",
        "    # Update the alpha parameter\n",
        "    clf_params = common_params.copy()\n",
        "    clf_params['alpha'] = alpha\n",
        "\n",
        "    # Initialize and train the classifier\n",
        "    clf = MLPClassifier(**clf_params)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Collect metrics\n",
        "    n_iter = clf.n_iter_\n",
        "    train_acc = clf.score(X_train, y_train)\n",
        "    test_acc = clf.score(X_test, y_test)\n",
        "    best_loss = clf.best_loss_\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'alpha': alpha,\n",
        "        'iterations': n_iter,\n",
        "        'train_accuracy': train_acc,\n",
        "        'test_accuracy': test_acc,\n",
        "        'best_loss': best_loss,\n",
        "        'loss_curve': clf.loss_curve_  # Store loss curve\n",
        "    })\n",
        "\n",
        "# Create a table of results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Results Table:\")\n",
        "print(results_df[['alpha', 'iterations', 'train_accuracy', 'test_accuracy', 'best_loss']])\n",
        "\n",
        "# Determine the best regularization value\n",
        "best_result = max(results, key=lambda x: x['test_accuracy'])\n",
        "best_alpha = best_result['alpha']\n",
        "print(f\"\\nBest regularization value (alpha): {best_alpha}\")\n",
        "\n",
        "# For the best alpha, plot loss vs. epochs\n",
        "plt.figure(figsize=(8, 6))\n",
        "epochs = np.arange(1, len(best_result['loss_curve']) + 1)\n",
        "plt.plot(epochs, best_result['loss_curve'], marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Loss vs. Epochs for Training Set (alpha={best_alpha})')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcLCxdKzvpS_"
      },
      "source": [
        "Using the Iris dataset, the code trains an `MLPClassifier` to evaluate the effects of L2 loss regularization by experimenting with various alpha values (0.1, 0.01, 0.001, 0.0001, and 0.00001). A consistent train-test split is used to ensure fair comparison. Based on 227 iterations until convergence, the results show that an alpha of 0.001 offers the greatest balance between training accuracy (98.33%) and test accuracy (96.67%). Lower accuracies are a sign of underfitting, which is caused by higher alpha values like 0.1. Effective learning is demonstrated by the best alpha's loss curve, which displays a consistent drop in loss over epochs. This experiment highlights the significance of fine-tuning the regularization value by showing that moderate regularization enhances generalization without requiring an excessive amount of training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOteTlV6S0bq"
      },
      "source": [
        "## 2 Hyperparameters\n",
        "In this section we use the [Vowel Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/vowel.arff) to consider the hyperparameters of learning rate, number of hidden nodes, and momentum.\n",
        "\n",
        "### 2.1 (10%) Vowel Dataset Questions\n",
        "- Give the baseline accuracies for the Iris and Vowel datasets. Baseline accuracy is what you would get if the model just outputs the majority class of the data set (i.e. the output value which occurs most often). These two data sets are not great example for this as they have an equal amount of each class, which is not typical.\n",
        "- Discuss why the vowel data set will probably have lower accuracy than Iris.\n",
        "- Consider which of the vowel dataset's input features you should not use in training and discuss why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmq9GSbJS8k2"
      },
      "source": [
        "The baseline accuracy is directly correlated with the number of classes in each dataset because each target class has the same amount of rows in both datasets. There are three classes for the Iris dataset. Therefore, the baseline accuracy is 1/3 = 33.3%. Since there are 11 classes in the Vowel dataset, the baseline accuracy is 1/11 = 9.1%.\n",
        "\n",
        "Given that there are more opportunities for error in the vowel dataset than in the Iris dataset, the accuracy of the vowel dataset is likely to be lower. The model needs to be more precise and able to distinguish between additional target classes. Because there were just two incorrect answers in the Iris dataset, the model had less work to do. On the other hand, the Vowel dataset has 10 erroneous answers, so the model will have to learn more and be more comprehensive and exact.\n",
        "\n",
        "It seems that there is no association between the \"Train or Test,\" \"Speaker Number,\" and \"Sex\" attributes and the target, based on an analysis of the sweetviz output. Upon closer examination, it appears that every speaker is either a male or a female train or test, with an equal representation of each \"Class\". Consequently, these three traits do not contribute any pertinent information to the model because they are uncorrelated with the target \"Class\". As such, their inclusion in the training data is inappropriate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRG42TgSR4x"
      },
      "source": [
        "### 2.2 (10%) Learning Rate\n",
        "Load the [Vowel Dataset](https://raw.githubusercontent.com/cs472ta/CS472/master/datasets/vowel.arff). Drop any features which you explained above as being inappropriate for training.\n",
        "\n",
        "Hints: Consider the Pandas drop method for dropping columns. When you want to transform features in your data set there are lots of approaches. You could edit the arff file directly, or make the transforms in your code.  The Pandas replace method is nice for that. For example, if you wanted to change the vowel data set gender feature in a Pandas dataframe to 0/1 you could do the following:\n",
        "\n",
        "vowel_df['Sex'] = vowel_df['Sex'].str.decode('utf-8')   //Changes the byte code data into a normal string, b'Male' becomes \"Male\"\\\n",
        "vowel_df = vowel_df.replace('Male', 0)\\\n",
        "vowel_df = vowel_df.replace('Female', 1)\n",
        "\n",
        "- Use one layer of hidden nodes with the number of hidden nodes being twice the number of inputs.\n",
        "- Use a random 75/25 split of the data for the training/test set.\n",
        "- Do not use early stopping.\n",
        "- Try at least 5 different learning rates (LR) from very small (e.g. .001) to pretty big (e.g. 10). Each LR will require a different number of epochs to learn. LR effects both accuracy and time required for learning.\n",
        "- Create a table which includes a row for each LR.  Your table columns should be LR, # epochs to learn the model, final training set accuracy and final test set accuracy.  As learning rates get smaller, it usually takes more epochs to learn. If your model is stopping learning too soon (converging) by hitting max_iterations (in this case and in experiments below), then you need to increase your max_iterations parameter in order to give your model more learning time.  To keep things faster, you don't need to increase max_iter past 1000 if you don't want to, but point out when more iterations may have given improvement.\n",
        "\n",
        "In real testing one averages the results of multiple trials per LR (and other parameters) with different intitial conditions (training/test split, initial weights, etc.). That gives more accurate results but is not required for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBGUn43ASiXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6a20ef-2455-4f09-f3f1-504addfc62df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-16724ccf0f36>:15: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Learning Rate  # Epochs  Training Accuracy  Test Accuracy\n",
            "0          0.001      1000           0.901617       0.798387\n",
            "1          0.010       789           1.000000       0.907258\n",
            "2          0.100       304           1.000000       0.899194\n",
            "3          1.000       101           0.919137       0.822581\n",
            "4         10.000       184           0.553908       0.463710\n"
          ]
        }
      ],
      "source": [
        "# Train with different learning rates\n",
        "\n",
        "from scipy.io import arff\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Vowel Dataset\n",
        "vowel_arff = arff.loadarff('vowel.arff')\n",
        "vowel_df = pd.DataFrame(vowel_arff[0])\n",
        "\n",
        "# Decode byte strings to regular strings\n",
        "vowel_df['Sex'] = vowel_df['Sex'].str.decode('utf-8')\n",
        "vowel_df['Class'] = vowel_df['Class'].str.decode('utf-8')\n",
        "\n",
        "# Encode 'Sex' feature as 0 (Male) and 1 (Female)\n",
        "vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Drop irrelevant features\n",
        "vowel_df = vowel_df.drop(['Train or Test', 'Speaker Number'], axis=1)\n",
        "\n",
        "# Define feature columns (including 'Sex')\n",
        "X_columns = ['Sex'] + [f'Feature {i}' for i in range(10)]\n",
        "X = vowel_df[X_columns]\n",
        "y = vowel_df['Class']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets (75/25 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "n_inputs = X_train.shape[1]  # 11 features\n",
        "n_hidden_units = n_inputs * 2  # 22 hidden nodes\n",
        "\n",
        "# Define different learning rates to try\n",
        "learning_rates = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "# Store the results\n",
        "results = []\n",
        "\n",
        "# Loop over different learning rates\n",
        "for lr in learning_rates:\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=[n_hidden_units],\n",
        "        activation='logistic',\n",
        "        solver='sgd',\n",
        "        alpha=0,\n",
        "        batch_size=1,\n",
        "        learning_rate_init=lr,\n",
        "        shuffle=True,\n",
        "        momentum=0,\n",
        "        n_iter_no_change=50,\n",
        "        max_iter=1000,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Record the number of epochs, training accuracy, and test accuracy\n",
        "    n_epochs = clf.n_iter_\n",
        "    train_accuracy = clf.score(X_train, y_train)\n",
        "    test_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Learning Rate': lr,\n",
        "        '# Epochs': n_epochs,\n",
        "        'Training Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy\n",
        "    })\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjJBIwktlxt"
      },
      "source": [
        "The 'Sex' feature is numerically encoded and superfluous features are removed as part of the preprocessing and loading of the Vowel Dataset. It divides the data into training and test sets using a 75/25 split and applies `StandardScaler` to scale the features. One hidden layer in an MLPClassifier neural network is set up with twice as many input features (22 nodes). Different learning rates, ranging from 0.001 to 10, are used to train the model.\n",
        "\n",
        "The findings demonstrate that the highest test accuracy (90.7%) in 789 epochs and perfect training accuracy are obtained with a learning rate of 0.01. Extremely high learning rates (e.g., 10) result in subpar performance because of convergence problems, but lower learning rates require more epochs and may underfit. This demonstrates the importance of choosing an appropriate learning rate for optimal model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-nUu5Txtlxt"
      },
      "source": [
        "### 2.3 (10%) Number of Hidden Nodes\n",
        "\n",
        "Using the best LR you discovered, experiment with different numbers of hidden nodes.\n",
        "\n",
        "- Start with 1 hidden node, then 2, and then double them for each test until you get no more improvement in accuracy.\n",
        "- Create a table just like above, except with # of hidden nodes rather than LR.\n",
        "\n",
        "In general, whenever you are testing a parameter such as # of hidden nodes, keep testing values until no more improvement is found. For example, if 20 hidden nodes did better than 10, you would not stop at 20, but would try 40, etc., until you no longer got improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLqeA1iutlxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf081ad-9464-496c-8160-86f998f7ee1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0685245cc2a5>:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Hidden Nodes  # Epochs  Training Accuracy  Test Accuracy\n",
            "0             1       662           0.270889       0.225806\n",
            "1             2       559           0.564690       0.532258\n",
            "2             4      1000           0.757412       0.661290\n",
            "3             8      1000           0.893531       0.786290\n",
            "4            16      1000           1.000000       0.862903\n",
            "5            32       720           1.000000       0.935484\n",
            "6            64       621           1.000000       0.939516\n",
            "7           128       687           1.000000       0.939516\n"
          ]
        }
      ],
      "source": [
        "# Train with different numbers of hidden nodes\n",
        "\n",
        "# Load the Vowel Dataset\n",
        "vowel_arff = arff.loadarff('vowel.arff')\n",
        "vowel_df = pd.DataFrame(vowel_arff[0])\n",
        "\n",
        "# Decode byte strings to regular strings\n",
        "vowel_df['Sex'] = vowel_df['Sex'].str.decode('utf-8')\n",
        "vowel_df['Class'] = vowel_df['Class'].str.decode('utf-8')\n",
        "\n",
        "# Encode 'Sex' feature as 0 (Male) and 1 (Female)\n",
        "vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Drop irrelevant features\n",
        "vowel_df = vowel_df.drop(['Train or Test', 'Speaker Number'], axis=1)\n",
        "\n",
        "# Define feature columns (including 'Sex')\n",
        "X_columns = ['Sex'] + [f'Feature {i}' for i in range(10)]\n",
        "X = vowel_df[X_columns]\n",
        "y = vowel_df['Class']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets (75/25 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Use the best learning rate found earlier\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Define different numbers of hidden nodes to try\n",
        "hidden_node_counts = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "\n",
        "# Loop over different numbers of hidden nodes\n",
        "for n_hidden_units in hidden_node_counts:\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=[n_hidden_units],\n",
        "        activation='logistic',\n",
        "        solver='sgd',\n",
        "        alpha=0,\n",
        "        batch_size=1,\n",
        "        learning_rate_init=learning_rate,\n",
        "        shuffle=True,\n",
        "        momentum=0,\n",
        "        n_iter_no_change=50,\n",
        "        max_iter=1000,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Record the number of epochs, training accuracy, and test accuracy\n",
        "    n_epochs = clf.n_iter_\n",
        "    train_accuracy = clf.score(X_train, y_train)\n",
        "    test_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Hidden Nodes': n_hidden_units,\n",
        "        '# Epochs': n_epochs,\n",
        "        'Training Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy\n",
        "    })\n",
        "\n",
        "    # Check for no improvement in test accuracy\n",
        "    if len(results) > 1 and test_accuracy <= results[-2]['Test Accuracy']:\n",
        "        # Stop testing larger networks if no improvement\n",
        "        break\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLliSMtXtlxt"
      },
      "source": [
        "Training and test accuracies both greatly improve as the number of hidden nodes rises from 1 to 128. The model performs poorly with only 1 hidden node (training accuracy ~27%, test accuracy ~ 22%). Gradually improving performance, doubling the nodes results in perfect training accuracy at 16 nodes and a test accuracy of approximately 86%. Test accuracy peaks at about 93.5% at 32 hidden nodes, while increments to 64 and 128 nodes show negligible improvement, suggesting a plateau. After achieving ideal hidden nodes, the number of epochs needed to converge varies but generally reduces, indicating faster learning with a more appropriate network size. This illustrates that adding hidden nodes increases model capacity only so much; beyond that, overfitting could happen without yielding further improvements in test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v72ryeHXtlxu"
      },
      "source": [
        "### 2.4 (10%) Momentum\n",
        "\n",
        "Try at least 5 different momentum terms between 0 and just less than 1 using the best number of hidden nodes and LR from your earlier experiments.\n",
        "\n",
        "- Create a table just like above, except with momentum values rather than LR or number of hidden nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiEBTL6Vtlxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb757f25-dde1-4e04-896f-3dca05fac301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-f3f29ea2223b>:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Momentum  # Epochs  Training Accuracy  Test Accuracy\n",
            "0      0.00       621           1.000000       0.939516\n",
            "1      0.30       519           1.000000       0.943548\n",
            "2      0.60       375           1.000000       0.951613\n",
            "3      0.90       197           1.000000       0.959677\n",
            "4      0.99       162           0.946092       0.875000\n"
          ]
        }
      ],
      "source": [
        "# Train with different momentum values\n",
        "\n",
        "# Load the Vowel Dataset\n",
        "vowel_arff = arff.loadarff('vowel.arff')\n",
        "vowel_df = pd.DataFrame(vowel_arff[0])\n",
        "\n",
        "# Decode byte strings to regular strings\n",
        "vowel_df['Sex'] = vowel_df['Sex'].str.decode('utf-8')\n",
        "vowel_df['Class'] = vowel_df['Class'].str.decode('utf-8')\n",
        "\n",
        "# Encode 'Sex' feature as 0 (Male) and 1 (Female)\n",
        "vowel_df['Sex'] = vowel_df['Sex'].replace({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Drop irrelevant features\n",
        "vowel_df = vowel_df.drop(['Train or Test', 'Speaker Number'], axis=1)\n",
        "\n",
        "# Define feature columns (including 'Sex')\n",
        "X_columns = ['Sex'] + [f'Feature {i}' for i in range(10)]\n",
        "X = vowel_df[X_columns]\n",
        "y = vowel_df['Class']\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets (75/25 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Use the best learning rate and number of hidden nodes from earlier experiments\n",
        "learning_rate = 0.01\n",
        "num_hidden_nodes = 64\n",
        "\n",
        "# Define different momentum values to try\n",
        "momentum_values = [0, 0.3, 0.6, 0.9, 0.99]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Loop over different momentum values\n",
        "for momentum in momentum_values:\n",
        "    clf = MLPClassifier(\n",
        "        hidden_layer_sizes=[num_hidden_nodes],\n",
        "        activation='logistic',\n",
        "        solver='sgd',\n",
        "        alpha=0,\n",
        "        batch_size=1,\n",
        "        learning_rate_init=learning_rate,\n",
        "        shuffle=True,\n",
        "        momentum=momentum,\n",
        "        n_iter_no_change=50,\n",
        "        max_iter=1000,\n",
        "        verbose=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Record the number of epochs, training accuracy, and test accuracy\n",
        "    n_epochs = clf.n_iter_\n",
        "    train_accuracy = clf.score(X_train, y_train)\n",
        "    test_accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Momentum': momentum,\n",
        "        '# Epochs': n_epochs,\n",
        "        'Training Accuracy': train_accuracy,\n",
        "        'Test Accuracy': test_accuracy\n",
        "    })\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqidhekCtlxu"
      },
      "source": [
        "The drop in epochs from 621 to 197 indicates that increasing the momentum from 0 to 0.9 greatly shortens training time. This acceleration results from momentum accelerating convergence and assisting the optimizer in overcoming tiny local minima. Up to a momentum of 0.9, training accuracy stays perfect (100%) while test accuracy marginally increases (from roughly 93.95% to 95.97%), suggesting stronger generalization. Nevertheless, training accuracy falls to 94.6% and test accuracy reduces to 87.5% with an extremely high velocity of 0.99. This shows that excessive momentum can cause the optimizer to exceed the ideal weights, leading to inferior performance. Thus, a momentum value of approximately 0.9 provides the optimal trade-off between high accuracy and rapid training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hHxNgUCtlxv"
      },
      "source": [
        "### 2.5 (10%) Automatic Hyperparameter Discovery\n",
        "Using the vowel dataset, automatically adjust the LR, # of hidden nodes, and momentum using [grid and random search](https://scikit-learn.org/stable/modules/grid_search.html)\n",
        "- For grid search include the most promising hyperparameter values you used in your experiments above.  You may add others also.\n",
        "- Be patient as the grid search can take a while since it has to train all combinations of models. Don't use too many parameter options or it will be too slow.\n",
        "- Report your best hyperparameters and accuracy.  Unfortunately, you will not always get as high a score as you might expect.  This is in part due to the simplicity of the dataset.  It also teaches that in gerneral you should not blindly assume that a tool will get you the results you expect, and that you may need to consider multiple approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gDpb_0YvpTA",
        "outputId": "eb53198f-f34b-4289-ecb4-a8c7fa4f0dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hidden_layer_sizes': [64], 'learning_rate_init': 0.1, 'momentum': 0}\n",
            "0.6030303030303031\n"
          ]
        }
      ],
      "source": [
        "#Grid search for hyperparameters.\n",
        "#Here is one variation of code you could use for your grid search. You can try your own variation if you prefer.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = MLPClassifier(activation='logistic', solver='sgd',alpha=0,early_stopping=True, n_iter_no_change=10, batch_size=1)\n",
        "parameters = {'learning_rate_init':( 0.001, 0.01, 0.1), #You have to fill in the rest of your values for these lists\n",
        "              'hidden_layer_sizes': ([8], [32], [64]),\n",
        "              'momentum':(0, 0.9, 0.6)}\n",
        "grid = GridSearchCV(clf, parameters)\n",
        "grid.fit(X,y)    #This takes a while to run\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S026RVwuvpTB",
        "outputId": "b3377781-3402-4b2c-a35a-37055e18ee8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hidden_layer_sizes': [64], 'learning_rate_init': 0.08867278012078066, 'momentum': 0.4812915058023757}\n",
            "0.5979797979797981\n"
          ]
        }
      ],
      "source": [
        "#Randomized search for hyperparameters\n",
        "#Here is one variation of code you could use for your randomized search.\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "clf = MLPClassifier(activation='logistic', solver='sgd',alpha=0,early_stopping=True, n_iter_no_change=10, batch_size=1)\n",
        "distributions = dict(learning_rate_init=uniform(loc=0.01, scale=0.1), #loc is the min val, and loc + scale is the max val\n",
        "                    hidden_layer_sizes = ([8], [32], [64]), #since there is no distribution it samples these values uniformly\n",
        "                    momentum=uniform(loc=0,scale =.99))\n",
        "search = RandomizedSearchCV(clf, distributions, n_iter=10)\n",
        "search.fit(X,y)\n",
        "print(search.best_params_)\n",
        "print(search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "The `learning_rate_init`, `hidden_layer_sizes`, `momentum`, and `hidden_layer_sizes` hyperparameters are tested in an exhaustive manner using the grid search. With a best score of almost 0.603, it discovered that the optimal settings were `{'hidden_layer_sizes': [64], 'learning_rate_init': 0.1, and'momentum': 0}`. The randomized search, on the other hand, samples a predetermined number of parameter settings—in this case, 10 iterations—from predetermined distributions. It found an almost identical optimal arrangement, but with a little lower score of roughly 0.598. Randomized search is quicker and covers a wider range of values than grid search, which is comprehensive but takes a long time. While 64 was found to be the ideal hidden layer size by both approaches, more nuanced values for `learning_rate_init` and `momentum` were obtained by randomized search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIM0rEA9tlxu"
      },
      "source": [
        "## 3 Regression with MLPs\n",
        "\n",
        "### 3.1 (10%) - Learn a regression data set of your choice\n",
        "\n",
        "Train MLP on any real world data set that requires regression (i.e. has a real valued ouput) and discuss your effort and results.  While the [Irvine ML Repository](https://archive.ics.uci.edu) is a great resource, also onsider [Kaggle](https://www.kaggle.com) and [OpenML](https://openml.org) as other great places to find datasets.\n",
        "- Use [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) rather than MLPclassifier.  It has almost the exact same setup as MLPClassier except it uses the linear activation function for the output nodes and SSE as the loss function.  MLPClassier uses softmax activation for the output nodes and cross-entropy for the loss function.\n",
        "- Use any reasonable hyperparameters that you want.  \n",
        "- You will probably need to normalize input features.\n",
        "- It is not typically necessary to normalize the output.\n",
        "- Split into train and test and report the training and test set MAEs (Mean Absolute Error). For regression problems where we don't normalize the output, MAE is an intuitive measure as it shows exactly how much our output is off on average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFQv70W2VyqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0717eccf-f859-4397-a9a4-2098ff21050b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.65665508\n",
            "Iteration 2, loss = 0.54287376\n",
            "Iteration 3, loss = 0.50685434\n",
            "Iteration 4, loss = 0.48994205\n",
            "Iteration 5, loss = 0.48047100\n",
            "Iteration 6, loss = 0.47160562\n",
            "Iteration 7, loss = 0.46497281\n",
            "Iteration 8, loss = 0.45837982\n",
            "Iteration 9, loss = 0.45377854\n",
            "Iteration 10, loss = 0.44878188\n",
            "Iteration 11, loss = 0.44378116\n",
            "Iteration 12, loss = 0.44232003\n",
            "Iteration 13, loss = 0.43719200\n",
            "Iteration 14, loss = 0.43439908\n",
            "Iteration 15, loss = 0.43139480\n",
            "Iteration 16, loss = 0.42653191\n",
            "Iteration 17, loss = 0.42471671\n",
            "Iteration 18, loss = 0.42101077\n",
            "Iteration 19, loss = 0.41964104\n",
            "Iteration 20, loss = 0.41577352\n",
            "Iteration 21, loss = 0.41303284\n",
            "Iteration 22, loss = 0.41185966\n",
            "Iteration 23, loss = 0.40974522\n",
            "Iteration 24, loss = 0.40676032\n",
            "Iteration 25, loss = 0.40360708\n",
            "Iteration 26, loss = 0.40152040\n",
            "Iteration 27, loss = 0.40157042\n",
            "Iteration 28, loss = 0.40039809\n",
            "Iteration 29, loss = 0.39567719\n",
            "Iteration 30, loss = 0.39339151\n",
            "Iteration 31, loss = 0.39046483\n",
            "Iteration 32, loss = 0.38979619\n",
            "Iteration 33, loss = 0.38903685\n",
            "Iteration 34, loss = 0.38624105\n",
            "Iteration 35, loss = 0.38527139\n",
            "Iteration 36, loss = 0.38165912\n",
            "Iteration 37, loss = 0.38034951\n",
            "Iteration 38, loss = 0.38086511\n",
            "Iteration 39, loss = 0.37695412\n",
            "Iteration 40, loss = 0.37573430\n",
            "Iteration 41, loss = 0.37324521\n",
            "Iteration 42, loss = 0.37182635\n",
            "Iteration 43, loss = 0.37121119\n",
            "Iteration 44, loss = 0.37002820\n",
            "Iteration 45, loss = 0.36660815\n",
            "Iteration 46, loss = 0.36566146\n",
            "Iteration 47, loss = 0.36460879\n",
            "Iteration 48, loss = 0.36342756\n",
            "Iteration 49, loss = 0.36020703\n",
            "Iteration 50, loss = 0.36096118\n",
            "Iteration 51, loss = 0.35870089\n",
            "Iteration 52, loss = 0.35691780\n",
            "Iteration 53, loss = 0.35797666\n",
            "Iteration 54, loss = 0.35498659\n",
            "Iteration 55, loss = 0.35466102\n",
            "Iteration 56, loss = 0.35253351\n",
            "Iteration 57, loss = 0.35040503\n",
            "Iteration 58, loss = 0.35102841\n",
            "Iteration 59, loss = 0.35309544\n",
            "Iteration 60, loss = 0.35167020\n",
            "Iteration 61, loss = 0.34766034\n",
            "Iteration 62, loss = 0.34764694\n",
            "Iteration 63, loss = 0.34404817\n",
            "Iteration 64, loss = 0.34900644\n",
            "Iteration 65, loss = 0.34709884\n",
            "Iteration 66, loss = 0.34048169\n",
            "Iteration 67, loss = 0.34082373\n",
            "Iteration 68, loss = 0.33788628\n",
            "Iteration 69, loss = 0.33741440\n",
            "Iteration 70, loss = 0.33558509\n",
            "Iteration 71, loss = 0.33379533\n",
            "Iteration 72, loss = 0.33263063\n",
            "Iteration 73, loss = 0.33119819\n",
            "Iteration 74, loss = 0.33015757\n",
            "Iteration 75, loss = 0.33090547\n",
            "Iteration 76, loss = 0.32822225\n",
            "Iteration 77, loss = 0.32633722\n",
            "Iteration 78, loss = 0.32573849\n",
            "Iteration 79, loss = 0.32421334\n",
            "Iteration 80, loss = 0.32429426\n",
            "Iteration 81, loss = 0.32502010\n",
            "Iteration 82, loss = 0.32024574\n",
            "Iteration 83, loss = 0.32033278\n",
            "Iteration 84, loss = 0.32063869\n",
            "Iteration 85, loss = 0.32188205\n",
            "Iteration 86, loss = 0.32036416\n",
            "Iteration 87, loss = 0.31670243\n",
            "Iteration 88, loss = 0.31405722\n",
            "Iteration 89, loss = 0.31529918\n",
            "Iteration 90, loss = 0.31798607\n",
            "Iteration 91, loss = 0.31424233\n",
            "Iteration 92, loss = 0.31513329\n",
            "Iteration 93, loss = 0.31109719\n",
            "Iteration 94, loss = 0.30960310\n",
            "Iteration 95, loss = 0.30873039\n",
            "Iteration 96, loss = 0.30942322\n",
            "Iteration 97, loss = 0.30643994\n",
            "Iteration 98, loss = 0.30622285\n",
            "Iteration 99, loss = 0.30465880\n",
            "Iteration 100, loss = 0.30346501\n",
            "Iteration 101, loss = 0.30242655\n",
            "Iteration 102, loss = 0.30651677\n",
            "Iteration 103, loss = 0.30291075\n",
            "Iteration 104, loss = 0.30265975\n",
            "Iteration 105, loss = 0.30203386\n",
            "Iteration 106, loss = 0.30050843\n",
            "Iteration 107, loss = 0.29708070\n",
            "Iteration 108, loss = 0.29886971\n",
            "Iteration 109, loss = 0.29860970\n",
            "Iteration 110, loss = 0.29723250\n",
            "Iteration 111, loss = 0.29689143\n",
            "Iteration 112, loss = 0.29657545\n",
            "Iteration 113, loss = 0.29324563\n",
            "Iteration 114, loss = 0.29288529\n",
            "Iteration 115, loss = 0.29222343\n",
            "Iteration 116, loss = 0.29191906\n",
            "Iteration 117, loss = 0.29216750\n",
            "Iteration 118, loss = 0.29348575\n",
            "Iteration 119, loss = 0.29164785\n",
            "Iteration 120, loss = 0.28808262\n",
            "Iteration 121, loss = 0.28704060\n",
            "Iteration 122, loss = 0.28651353\n",
            "Iteration 123, loss = 0.28867193\n",
            "Iteration 124, loss = 0.28853391\n",
            "Iteration 125, loss = 0.28330879\n",
            "Iteration 126, loss = 0.28289470\n",
            "Iteration 127, loss = 0.28250240\n",
            "Iteration 128, loss = 0.28466888\n",
            "Iteration 129, loss = 0.28511415\n",
            "Iteration 130, loss = 0.28081365\n",
            "Iteration 131, loss = 0.27952167\n",
            "Iteration 132, loss = 0.27977870\n",
            "Iteration 133, loss = 0.28186568\n",
            "Iteration 134, loss = 0.27978247\n",
            "Iteration 135, loss = 0.28130850\n",
            "Iteration 136, loss = 0.27816749\n",
            "Iteration 137, loss = 0.27935795\n",
            "Iteration 138, loss = 0.28371627\n",
            "Iteration 139, loss = 0.27662675\n",
            "Iteration 140, loss = 0.27603317\n",
            "Iteration 141, loss = 0.27648205\n",
            "Iteration 142, loss = 0.27460331\n",
            "Iteration 143, loss = 0.27286670\n",
            "Iteration 144, loss = 0.27103167\n",
            "Iteration 145, loss = 0.27560371\n",
            "Iteration 146, loss = 0.27225409\n",
            "Iteration 147, loss = 0.27311484\n",
            "Iteration 148, loss = 0.27204917\n",
            "Iteration 149, loss = 0.27056716\n",
            "Iteration 150, loss = 0.26798616\n",
            "Iteration 151, loss = 0.26633134\n",
            "Iteration 152, loss = 0.26807068\n",
            "Iteration 153, loss = 0.26756433\n",
            "Iteration 154, loss = 0.26623153\n",
            "Iteration 155, loss = 0.26749424\n",
            "Iteration 156, loss = 0.26660116\n",
            "Iteration 157, loss = 0.26505337\n",
            "Iteration 158, loss = 0.26416279\n",
            "Iteration 159, loss = 0.26475463\n",
            "Iteration 160, loss = 0.26729755\n",
            "Iteration 161, loss = 0.26315372\n",
            "Iteration 162, loss = 0.26131227\n",
            "Iteration 163, loss = 0.26151619\n",
            "Iteration 164, loss = 0.26032401\n",
            "Iteration 165, loss = 0.26034262\n",
            "Iteration 166, loss = 0.25862159\n",
            "Iteration 167, loss = 0.25786639\n",
            "Iteration 168, loss = 0.25769638\n",
            "Iteration 169, loss = 0.25721084\n",
            "Iteration 170, loss = 0.25867320\n",
            "Iteration 171, loss = 0.25681783\n",
            "Iteration 172, loss = 0.25766237\n",
            "Iteration 173, loss = 0.25391933\n",
            "Iteration 174, loss = 0.25806464\n",
            "Iteration 175, loss = 0.26175355\n",
            "Iteration 176, loss = 0.25672204\n",
            "Iteration 177, loss = 0.25661398\n",
            "Iteration 178, loss = 0.25382200\n",
            "Iteration 179, loss = 0.25157487\n",
            "Iteration 180, loss = 0.25409223\n",
            "Iteration 181, loss = 0.25112787\n",
            "Iteration 182, loss = 0.25251335\n",
            "Iteration 183, loss = 0.25250045\n",
            "Iteration 184, loss = 0.25643484\n",
            "Iteration 185, loss = 0.25407545\n",
            "Iteration 186, loss = 0.25168208\n",
            "Iteration 187, loss = 0.25362165\n",
            "Iteration 188, loss = 0.25563995\n",
            "Iteration 189, loss = 0.25131449\n",
            "Iteration 190, loss = 0.25329515\n",
            "Iteration 191, loss = 0.25496181\n",
            "Iteration 192, loss = 0.25028971\n",
            "Iteration 193, loss = 0.25137771\n",
            "Iteration 194, loss = 0.24741424\n",
            "Iteration 195, loss = 0.25243816\n",
            "Iteration 196, loss = 0.24744749\n",
            "Iteration 197, loss = 0.24898115\n",
            "Iteration 198, loss = 0.24650270\n",
            "Iteration 199, loss = 0.24766158\n",
            "Iteration 200, loss = 0.24403500\n",
            "Iteration 201, loss = 0.24542386\n",
            "Iteration 202, loss = 0.24205473\n",
            "Iteration 203, loss = 0.24860309\n",
            "Iteration 204, loss = 0.24551070\n",
            "Iteration 205, loss = 0.24241344\n",
            "Iteration 206, loss = 0.24483622\n",
            "Iteration 207, loss = 0.24166690\n",
            "Iteration 208, loss = 0.24112492\n",
            "Iteration 209, loss = 0.23874168\n",
            "Iteration 210, loss = 0.23863233\n",
            "Iteration 211, loss = 0.24149491\n",
            "Iteration 212, loss = 0.23921555\n",
            "Iteration 213, loss = 0.23896252\n",
            "Iteration 214, loss = 0.24189768\n",
            "Iteration 215, loss = 0.23680037\n",
            "Iteration 216, loss = 0.23652678\n",
            "Iteration 217, loss = 0.23785998\n",
            "Iteration 218, loss = 0.23410717\n",
            "Iteration 219, loss = 0.24381352\n",
            "Iteration 220, loss = 0.23969091\n",
            "Iteration 221, loss = 0.23539346\n",
            "Iteration 222, loss = 0.23466649\n",
            "Iteration 223, loss = 0.23682514\n",
            "Iteration 224, loss = 0.23802958\n",
            "Iteration 225, loss = 0.23641424\n",
            "Iteration 226, loss = 0.23502815\n",
            "Iteration 227, loss = 0.23605153\n",
            "Iteration 228, loss = 0.23246688\n",
            "Iteration 229, loss = 0.23131215\n",
            "Iteration 230, loss = 0.23254318\n",
            "Iteration 231, loss = 0.23447081\n",
            "Iteration 232, loss = 0.23513972\n",
            "Iteration 233, loss = 0.23261322\n",
            "Iteration 234, loss = 0.23506385\n",
            "Iteration 235, loss = 0.23216900\n",
            "Iteration 236, loss = 0.23411250\n",
            "Iteration 237, loss = 0.22989991\n",
            "Iteration 238, loss = 0.22713999\n",
            "Iteration 239, loss = 0.22933310\n",
            "Iteration 240, loss = 0.23005355\n",
            "Iteration 241, loss = 0.22878046\n",
            "Iteration 242, loss = 0.23042084\n",
            "Iteration 243, loss = 0.23142780\n",
            "Iteration 244, loss = 0.23029397\n",
            "Iteration 245, loss = 0.22801407\n",
            "Iteration 246, loss = 0.23102136\n",
            "Iteration 247, loss = 0.22582567\n",
            "Iteration 248, loss = 0.22718277\n",
            "Iteration 249, loss = 0.22489334\n",
            "Iteration 250, loss = 0.23349996\n",
            "Iteration 251, loss = 0.22669431\n",
            "Iteration 252, loss = 0.22508596\n",
            "Iteration 253, loss = 0.22288885\n",
            "Iteration 254, loss = 0.22348505\n",
            "Iteration 255, loss = 0.22871073\n",
            "Iteration 256, loss = 0.22500621\n",
            "Iteration 257, loss = 0.22805841\n",
            "Iteration 258, loss = 0.22990944\n",
            "Iteration 259, loss = 0.22631566\n",
            "Iteration 260, loss = 0.22327785\n",
            "Iteration 261, loss = 0.22430849\n",
            "Iteration 262, loss = 0.22215122\n",
            "Iteration 263, loss = 0.22000659\n",
            "Iteration 264, loss = 0.22234622\n",
            "Iteration 265, loss = 0.22166220\n",
            "Iteration 266, loss = 0.22399945\n",
            "Iteration 267, loss = 0.22157270\n",
            "Iteration 268, loss = 0.22195227\n",
            "Iteration 269, loss = 0.21927041\n",
            "Iteration 270, loss = 0.22178564\n",
            "Iteration 271, loss = 0.22289110\n",
            "Iteration 272, loss = 0.22005304\n",
            "Iteration 273, loss = 0.21935879\n",
            "Iteration 274, loss = 0.21704948\n",
            "Iteration 275, loss = 0.21992481\n",
            "Iteration 276, loss = 0.21558258\n",
            "Iteration 277, loss = 0.21604262\n",
            "Iteration 278, loss = 0.21677142\n",
            "Iteration 279, loss = 0.21516482\n",
            "Iteration 280, loss = 0.21590464\n",
            "Iteration 281, loss = 0.21676375\n",
            "Iteration 282, loss = 0.21729635\n",
            "Iteration 283, loss = 0.21651413\n",
            "Iteration 284, loss = 0.21481065\n",
            "Iteration 285, loss = 0.21292693\n",
            "Iteration 286, loss = 0.22033481\n",
            "Iteration 287, loss = 0.21931877\n",
            "Iteration 288, loss = 0.21741672\n",
            "Iteration 289, loss = 0.21698495\n",
            "Iteration 290, loss = 0.22033043\n",
            "Iteration 291, loss = 0.21454375\n",
            "Iteration 292, loss = 0.21470598\n",
            "Iteration 293, loss = 0.21655875\n",
            "Iteration 294, loss = 0.21740207\n",
            "Iteration 295, loss = 0.21742678\n",
            "Iteration 296, loss = 0.21626541\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Training MAE: €1028.23\n",
            "Test MAE: €1949.38\n"
          ]
        }
      ],
      "source": [
        "# Load and Learn a real world regression data set\n",
        "# To calculate MAE you could do a variation of the following\n",
        "\n",
        "# Load the Bank Dataset\n",
        "bank_df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# Select the target variable 'balance' for regression\n",
        "# Drop the original target 'y' as it's not needed\n",
        "bank_df = bank_df.drop('y', axis=1)\n",
        "\n",
        "# Examine the distribution of 'balance'\n",
        "plt.hist(bank_df['balance'], bins=50)\n",
        "plt.title('Distribution of Balance')\n",
        "plt.xlabel('Balance')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Handle outliers by capping the 'balance' at the 99th percentile\n",
        "balance_cap = bank_df['balance'].quantile(0.99)\n",
        "bank_df['balance'] = np.where(bank_df['balance'] > balance_cap, balance_cap, bank_df['balance'])\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing',\n",
        "                       'loan', 'contact', 'month', 'poutcome']\n",
        "numerical_columns = ['age', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "ohe.fit(bank_df[categorical_columns])\n",
        "ohe_feature_names = ohe.get_feature_names_out(categorical_columns)\n",
        "bank_ohe = pd.DataFrame(ohe.transform(bank_df[categorical_columns]), columns=ohe_feature_names)\n",
        "\n",
        "# Combine numerical features and one-hot encoded features\n",
        "bank_numeric = bank_df[numerical_columns + ['balance']].reset_index(drop=True)\n",
        "bank_processed = pd.concat([bank_numeric, bank_ohe], axis=1)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = bank_processed.drop('balance', axis=1)\n",
        "y = bank_processed['balance']\n",
        "\n",
        "# Normalize input features\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "# Scale the target variable\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the MLPRegressor with increased max_iter\n",
        "regressor = MLPRegressor(\n",
        "    hidden_layer_sizes=[64],\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    learning_rate_init=0.001,\n",
        "    max_iter=1000,  # Increased from 500 to 1000\n",
        "    random_state=42,\n",
        "    verbose=True\n",
        ")\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate MAE for training and test sets\n",
        "y_train_pred_scaled = regressor.predict(X_train)\n",
        "y_test_pred_scaled = regressor.predict(X_test)\n",
        "\n",
        "# Inverse transform the scaled predictions\n",
        "y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).ravel()\n",
        "y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Compute MAE\n",
        "train_mae = mean_absolute_error(scaler_y.inverse_transform(y_train.reshape(-1,1)), y_train_pred)\n",
        "test_mae = mean_absolute_error(scaler_y.inverse_transform(y_test.reshape(-1,1)), y_test_pred)\n",
        "\n",
        "print(f\"Training MAE: €{train_mae:.2f}\")\n",
        "print(f\"Test MAE: €{test_mae:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcr9DW3bvpTB"
      },
      "source": [
        "Using an `MLPRegressor`, the algorithm aims to predict the \"balance\" in the bank dataset. In order to manage outliers, it preprocesses the data by capping the \"balance\" at the 99th percentile and using one-hot encoding for categorical variables. `StandardScaler` is used to standardize the target variable as well as the input features. The neural network is trained for a maximum of 1,000 iterations using a single hidden layer with 64 neurons.\n",
        "\n",
        "Despite these efforts, the training MAE is roughly €1,028, while the test MAE is around €1,949, showing poor generalization and likely overfitting. The model may not be adequately reflecting the underlying patterns, as indicated by the high MAE values. In order to enhance outcomes, contemplate conducting further feature engineering, modifying hyperparameters, or investigating substitute models such as ensemble approaches or linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5clkInRvpTB"
      },
      "source": [
        "### 3.2 (10%) - Other MLP Hyperparameters\n",
        "With the same data set, you may (not required) experiment with some of the hyperparameters you already did above (LR, hidden nodes, momentum, validation set parameters, regularization).  But for sure experiment with and discuss the results of the first two hyperparameters below (activation functions and multiple hidden layers).  We encourage you to experiment briefly with the others but they are not required.\n",
        "\n",
        "- different hidden layer activation functions (tanh, relu in addition to logistic) - Note that Sklean does not currently let you choose the output layer activation function.  It is automatically softmax for classification and linear for regression.\n",
        "- more than one hidden layer\n",
        "- solver - try adam and lbfgs in addition to sgd\n",
        "- batch size\n",
        "- learning rate adaptation - this is the schedule parameter which lets LR adapt during learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu1JE4vStlxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c97104e-d6be-4a99-ea97-c62f227c464d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Different Activation Functions:\n",
            "  Activation Function  Training MAE     Test MAE\n",
            "0            logistic    811.734339  2151.865917\n",
            "1                tanh    740.972690  2407.244275\n",
            "2                relu   1028.226186  1949.379520\n",
            "\n",
            "Results for Different Hidden Layer Configurations:\n",
            "  Hidden Layers  Training MAE     Test MAE\n",
            "0          [64]   1028.226186  1949.379520\n",
            "1      [64, 32]    740.974662  2272.912131\n",
            "2  [64, 32, 16]    672.302068  1850.445485\n"
          ]
        }
      ],
      "source": [
        "# Run with different hyperparameters\n",
        "\n",
        "# Load the Bank Dataset\n",
        "bank_df = pd.read_csv('bank.csv', sep=';')\n",
        "\n",
        "# Drop the original target 'y' and select 'balance' as the target variable\n",
        "bank_df = bank_df.drop('y', axis=1)\n",
        "\n",
        "# Handle outliers by capping 'balance' at the 99th percentile\n",
        "balance_cap = bank_df['balance'].quantile(0.99)\n",
        "bank_df['balance'] = np.where(bank_df['balance'] > balance_cap, balance_cap, bank_df['balance'])\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing',\n",
        "                       'loan', 'contact', 'month', 'poutcome']\n",
        "numerical_columns = ['age', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "bank_ohe = pd.DataFrame(ohe.fit_transform(bank_df[categorical_columns]),\n",
        "                        columns=ohe.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Combine numerical features and one-hot encoded features\n",
        "bank_numeric = bank_df[numerical_columns + ['balance']].reset_index(drop=True)\n",
        "bank_processed = pd.concat([bank_numeric, bank_ohe], axis=1)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = bank_processed.drop('balance', axis=1)\n",
        "y = bank_processed['balance']\n",
        "\n",
        "# Normalize input features\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "# Scale the target variable\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to train the model and record MAE\n",
        "def train_evaluate_model(hidden_layers, activation_func):\n",
        "    regressor = MLPRegressor(\n",
        "        hidden_layer_sizes=hidden_layers,\n",
        "        activation=activation_func,\n",
        "        solver='adam',\n",
        "        learning_rate_init=0.001,\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        verbose=False\n",
        "    )\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Reshape predictions to 2D arrays before inverse transforming\n",
        "    y_train_pred_scaled = regressor.predict(X_train).reshape(-1, 1)\n",
        "    y_test_pred_scaled = regressor.predict(X_test).reshape(-1, 1)\n",
        "\n",
        "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled).ravel()\n",
        "    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled).ravel()\n",
        "\n",
        "    y_train_actual = scaler_y.inverse_transform(y_train.reshape(-1, 1)).ravel()\n",
        "    y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
        "\n",
        "    train_mae = mean_absolute_error(y_train_actual, y_train_pred)\n",
        "    test_mae = mean_absolute_error(y_test_actual, y_test_pred)\n",
        "    return train_mae, test_mae\n",
        "\n",
        "# Experiment with different activation functions\n",
        "activation_functions = ['logistic', 'tanh', 'relu']\n",
        "results_activation = []\n",
        "\n",
        "for activation in activation_functions:\n",
        "    train_mae, test_mae = train_evaluate_model([64], activation)\n",
        "    results_activation.append({\n",
        "        'Activation Function': activation,\n",
        "        'Training MAE': train_mae,\n",
        "        'Test MAE': test_mae\n",
        "    })\n",
        "\n",
        "results_activation_df = pd.DataFrame(results_activation)\n",
        "print(\"Results for Different Activation Functions:\")\n",
        "print(results_activation_df)\n",
        "\n",
        "# Experiment with multiple hidden layers\n",
        "hidden_layer_configs = [[64], [64, 32], [64, 32, 16]]\n",
        "results_hidden_layers = []\n",
        "\n",
        "for layers in hidden_layer_configs:\n",
        "    train_mae, test_mae = train_evaluate_model(layers, 'relu')\n",
        "    results_hidden_layers.append({\n",
        "        'Hidden Layers': layers,\n",
        "        'Training MAE': train_mae,\n",
        "        'Test MAE': test_mae\n",
        "    })\n",
        "\n",
        "results_hidden_layers_df = pd.DataFrame(results_hidden_layers)\n",
        "print(\"\\nResults for Different Hidden Layer Configurations:\")\n",
        "print(results_hidden_layers_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HScVQasltlxv"
      },
      "source": [
        "In order to run regression on the 'balance' variable using an MLPRegressor neural network, the code fetches the Bank dataset. The method employs a one-hot encoding technique for categorical features, caps 'balance' at the 99th percentile to manage outliers, and scales both the target variable and features. The model explores with various hidden layer configurations ([64], [64, 32], [64, 32, 16]) and activation functions ('logistic', 'tanh','relu') to assess their effect on performance.\n",
        "\n",
        "The findings indicate that when compared to \"logistic\" and \"tanh,\" the \"relu\" activation function with a single hidden layer produces a higher training MAE (1028) but a lower test MAE (1949). The training MAE decreases with the number of hidden layers; it reaches its lowest value of 672 with three layers; however, the test MAE does not increase correspondingly, suggesting that overfitting may have occurred. The best test MAE (1850) suggests that while deeper networks can capture more complexity, they may not generalize better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 4. (Optional 20% extra credit) Code up your own MLP/Backprop learner\n",
        "Below is a scaffold you could use if you want. Requirements for this task:\n",
        "- Your model should support the methods shown in the example scaffold below.\n",
        "- Ability to create a network structure with at least one hidden layer and an arbitrary number of nodes. You may choose just one non-linear activation function for all hidden and output nodes if you want (e.g. sigmoid activation function where the loss is SSE rather than cross-entropy).\n",
        "- Random weight initialization with small random weights with 0 mean. Remember that every hidden and output node should have its own bias weight.\n",
        "- Use stochastic training updates: update weights after each training instance (i.e. not batch)\n",
        "- Option to include a momentum term\n",
        "- Your class can inherit from the relevant scikit-learn learners (e.g. data shuffling, etc.), but don't call any of the super methods to accomplish the core methods in the scaffold.\n",
        "- Run the Iris data set above with your Backprop version. Show and discuss your results and how they compare with the sklearn version.\n",
        "- Coding MLP is a good experience but is a little more challening than implementing other models so the extra credit points are higher than typical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rokMDC3Qtlxv"
      },
      "source": [
        "On the Iris dataset, scikit-learn's MLPClassifier obtained 100% accuracy, compared to the custom MLP's 68% test accuracy. This disparity most likely results from variations in optimization strategies and implementation specifics. Advanced features including adaptive learning rates, sophisticated weight initialization, and regularization techniques are all included in Scikit-learn's MLPClassifier, and they significantly improve convergence and generalization. Furthermore, the custome MLP may have drawbacks like inadequate training epochs, inadequate weight updates, or missing features like weight decay and early halting. Furthermore, the use of efficient algorithms and well optimized numerical stability is advantageous in the scikit-learn implementation. These elements support the superior performance of scikit-learn, underscoring the difficulties in reproducing intricate algorithms and the significance of careful execution in neural network training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn8n_iR8tlxv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class MLP(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, lr=0.1, momentum=0, shuffle=True, hidden_layer_widths=None, n_epochs=1000):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.shuffle = shuffle\n",
        "        self.hidden_layer_widths = hidden_layer_widths\n",
        "        self.n_epochs = n_epochs\n",
        "        self.activation_function = self._sigmoid\n",
        "        self.activation_derivative = self._sigmoid_derivative\n",
        "\n",
        "    def fit(self, X, y, initial_weights=None):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_outputs = len(np.unique(y))\n",
        "\n",
        "        # One-hot encode the targets\n",
        "        lb = LabelBinarizer()\n",
        "        y_encoded = lb.fit_transform(y)\n",
        "        self.classes_ = lb.classes_\n",
        "\n",
        "        # Define neural network architecture\n",
        "        layer_sizes = [n_features] + (self.hidden_layer_widths or [n_features * 2]) + [n_outputs]\n",
        "\n",
        "        # Initialize weights\n",
        "        self.weights = self.initialize_weights(layer_sizes) if initial_weights is None else initial_weights\n",
        "        weight_updates = [np.zeros_like(w[:-1]) for w in self.weights]\n",
        "        bias_updates = [np.zeros_like(w[-1]) for w in self.weights]\n",
        "\n",
        "        for epoch in range(self.n_epochs):\n",
        "            if self.shuffle:\n",
        "                X, y_encoded = shuffle(X, y_encoded, random_state=epoch)\n",
        "\n",
        "            for xi, target in zip(X, y_encoded):\n",
        "                # Forward pass\n",
        "                activations = [xi]\n",
        "                inputs = []\n",
        "                for w in self.weights:\n",
        "                    net_input = np.dot(activations[-1], w[:-1]) + w[-1]  # Separate bias\n",
        "                    inputs.append(net_input)\n",
        "                    activation = self.activation_function(net_input)\n",
        "                    activations.append(activation)\n",
        "\n",
        "                # Compute error (delta) at output layer\n",
        "                error = activations[-1] - target\n",
        "                deltas = [error * self.activation_derivative(inputs[-1])]\n",
        "\n",
        "                # Backward pass\n",
        "                for i in reversed(range(len(self.weights) - 1)):\n",
        "                    delta = np.dot(deltas[0], self.weights[i + 1][:-1].T) * self.activation_derivative(inputs[i])\n",
        "                    deltas.insert(0, delta)\n",
        "\n",
        "                # Update weights\n",
        "                for i in range(len(self.weights)):\n",
        "                    a = np.atleast_2d(activations[i])\n",
        "                    delta = np.atleast_2d(deltas[i])\n",
        "\n",
        "                    # Separate weight and bias updates\n",
        "                    weight_update = -self.lr * np.dot(a.T, delta)\n",
        "                    bias_update = -self.lr * delta.flatten()\n",
        "\n",
        "                    # Apply momentum\n",
        "                    weight_updates[i] = self.momentum * weight_updates[i] + weight_update\n",
        "                    bias_updates[i] = self.momentum * bias_updates[i] + bias_update\n",
        "\n",
        "                    # Update weights and biases\n",
        "                    self.weights[i][:-1] += weight_updates[i]  # Update weights\n",
        "                    self.weights[i][-1] += bias_updates[i]     # Update biases\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for xi in X:\n",
        "            activation = xi\n",
        "            for w in self.weights:\n",
        "                net_input = np.dot(activation, w[:-1]) + w[-1]\n",
        "                activation = self.activation_function(net_input)\n",
        "            y_pred.append(np.argmax(activation))\n",
        "        return self.classes_[y_pred]\n",
        "\n",
        "    def initialize_weights(self, layer_sizes):\n",
        "        weights = []\n",
        "        for i in range(len(layer_sizes) - 1):\n",
        "            limit = np.sqrt(6 / (layer_sizes[i] + layer_sizes[i + 1]))\n",
        "            w = np.random.uniform(-limit, limit, (layer_sizes[i] + 1, layer_sizes[i + 1]))  # +1 for bias\n",
        "            weights.append(w)\n",
        "        return weights\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.weights\n",
        "\n",
        "    # Activation functions\n",
        "    @staticmethod\n",
        "    def _sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def _sigmoid_derivative(x):\n",
        "        s = 1 / (1 + np.exp(-x))\n",
        "        return s * (1 - s)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Initialize and train custom MLP\n",
        "custom_mlp = MLP(lr=0.1, momentum=0.9, shuffle=True, hidden_layer_widths=[10], n_epochs=1000)\n",
        "custom_mlp.fit(X_train, y_train)\n",
        "custom_accuracy = custom_mlp.score(X_test, y_test)\n",
        "print(f\"Custom MLP Test Accuracy: {custom_accuracy:.2f}\")\n",
        "\n",
        "# Compare with scikit-learn's MLPClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "sklearn_mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', solver='sgd',\n",
        "                            learning_rate_init=0.1, momentum=0.9, max_iter=1000, random_state=42)\n",
        "sklearn_mlp.fit(X_train, y_train)\n",
        "sklearn_accuracy = sklearn_mlp.score(X_test, y_test)\n",
        "print(f\"Sklearn MLPClassifier Test Accuracy: {sklearn_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozjZZnekPIac",
        "outputId": "356e3c46-021e-4875-b8bf-8be3eff1fe6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom MLP Test Accuracy: 0.68\n",
            "Sklearn MLPClassifier Test Accuracy: 1.00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2.7.16 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2.7.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}